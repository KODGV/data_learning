{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 轮子：刻画变量的的绝对和相对的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To analyse categorical variables, we will create three custom functions.\n",
    "The first two functions displays bar labels in absolute and relative scale respectively. And the 3rd one creates a dataframe of absolute and relative and also generates abs and relative frequency plot for each variable.'''\n",
    "\n",
    "''' #1.Function for displaying bar labels in absolute scale.'''\n",
    "def abs_bar_labels():\n",
    "    plt.ylabel('Absolute Frequency')\n",
    "    plt.xticks(rotation = 0)\n",
    "    plt.yticks([])\n",
    "    # Set individual bar lebels in absolute number\n",
    "    for x in ax.patches:\n",
    "        ax.annotate(x.get_height(), \n",
    "        (x.get_x() + x.get_width()/2., x.get_height()), ha = 'center', va = 'center', xytext = (0, 7), \n",
    "        textcoords = 'offset points', fontsize = 14, color = 'black')\n",
    "    \n",
    "'''#2.Function for displaying bar lebels in relative scale.'''\n",
    "def pct_bar_labels():\n",
    "    plt.ylabel('Relative Frequency (%)')\n",
    "    plt.xticks(rotation = 0)\n",
    "    plt.yticks([])   \n",
    "    # Set individual bar lebels in proportional scale\n",
    "    for x in ax1.patches:\n",
    "        ax1.annotate(str(x.get_height()) + '%', \n",
    "        (x.get_x() + x.get_width()/2., x.get_height()), ha = 'center', va = 'center', xytext = (0, 7), \n",
    "        textcoords = 'offset points', fontsize = 14, color = 'black')\n",
    "         \n",
    "'''#3.Function to create a dataframe of absolute and relative frequency of each variable. And plot absolute and relative frequency.'''\n",
    "def absolute_and_relative_freq(variable):\n",
    "    global  ax, ax1 \n",
    "    # Dataframe of absolute and relative frequency\n",
    "    absolute_frequency = variable.value_counts()\n",
    "    # Will be multiplied by 100 and rounded to 2 decimal points for percentage\n",
    "    relative_frequency = round(variable.value_counts(normalize = True)*100, 2) \n",
    "    df = pd.DataFrame({'Absolute Frequency':absolute_frequency, 'Relative Frequency(%)':relative_frequency})\n",
    "    # This portion plots absolute frequency with bar labeled.\n",
    "    ax =  absolute_frequency.plot.bar()\n",
    "    plt.title('Absolute Frequency of %s' %variable.name) # Prints variable name as title in matplotlib\n",
    "    abs_bar_labels()  # Displays bar labels in abs scale.\n",
    "    plt.show()\n",
    "    # This portion plots relative frequency with bar labeled.\n",
    "    ax1 = relative_frequency.plot.bar()\n",
    "    plt.title('Relative Frequency of %s' %variable.name)\n",
    "    pct_bar_labels()\n",
    "    plt.show()\n",
    "    print('Absolute & Relative Frequency of',variable.name,':')\n",
    "    return display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用：用来查看单个变量内类别和数量的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Plot and count the number of survivors and victims in absolute and relative scale in the tragedy.'''\n",
    "merged.Survived.agg(absolute_and_relative_freq, axis = 0)\n",
    "absolute_and_relative_freq(merge_data.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 轮子：刻画变量的不平衡度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#2.Density plot with skewness.'''\n",
    "def density_plot_and_skewness(variable):\n",
    "    variable.plot.hist(density = True)\n",
    "    variable.plot.kde(style = 'k--')\n",
    "    plt.xlabel('%s'%variable.name)\n",
    "    plt.title('Distribution of %s with Density Plot & Histogram' %variable.name)\n",
    "    print('Skewness of ', variable.name, ':')\n",
    "    skewness = variable.skew()\n",
    "    return display(skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So what does the value of skewness suggest?\n",
    "\n",
    "If skewness is less than −1 or greater than +1, the distribution can be considered as highly skewed.\n",
    "\n",
    "If skewness is between −1 and −½ or between +½ and +1, the distribution can be considered as moderately skewed.\n",
    "\n",
    "And finally if skewness is between −½ and +½, the distribution can be considered as approximately symmetric.\n",
    "\n",
    "Findings: Density plot shows the mass of the distribution of Fare is heavily concentrated on the left of the figure due to very long tail on the right side. So it can be said that Fare is substantially skewed(positively) that is also supported by the calculated positive value of skewness of 4.368"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 轮子：对变量的分类聚合统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################分类变量######################################################\n",
    "'''Create a bucket Officer and put Dr, Rev, Col, Major, Capt titles into it.'''\n",
    "merged.Title.replace(to_replace = ['Dr', 'Rev', 'Col', 'Major', 'Capt'], value = 'Officer', inplace = True)\n",
    "\n",
    "'''Put Dona, Jonkheer, Countess, Sir, Lady, Don in bucket Aristocrat.'''\n",
    "merged.Title.replace(to_replace = ['Dona', 'Jonkheer', 'Countess', 'Sir', 'Lady', 'Don'], value = 'Aristocrat', inplace = True)\n",
    "\n",
    "'''Finally Replace Mlle and Ms with Miss. And Mme with Mrs.'''\n",
    "merged.Title.replace({'Mlle':'Miss', 'Ms':'Miss', 'Mme':'Mrs'}, inplace = True)\n",
    "####################################连续变量##########################################################\n",
    "'''Create bin categories for Age.'''\n",
    "label_names = ['infant','child','teenager','young_adult','adult','aged']\n",
    "\n",
    "'''Create range for each bin categories of Age.'''\n",
    "cut_points = [0,5,12,18,35,60,81]\n",
    "\n",
    "'''Create and view categorized Age with original Age.'''\n",
    "merged['Age_binned'] = pd.cut(merged.Age, cut_points, labels = label_names)\n",
    "display(merged[['Age', 'Age_binned']].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 轮子：离群点获取（箱图）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create a function to count total outliers. And plot variables with and without outliers.'''\n",
    "def outliers(variable):\n",
    "    # Calculate 1st, 3rd quartiles and iqr.\n",
    "    q1, q3 = variable.quantile(0.25), variable.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    # Calculate lower fence and upper fence for outliers\n",
    "    l_fence, u_fence = q1 - 1.5*iqr , q3 + 1.5*iqr   # Any values less than l_fence and greater than u_fence are outliers.\n",
    "    \n",
    "    # Observations that are outliers\n",
    "    outliers = variable[(variable<l_fence) | (variable>u_fence)]\n",
    "    print('Total Outliers of', variable.name,':', outliers.count())\n",
    "    \n",
    "    # Drop obsevations that are outliers\n",
    "    filtered = variable.drop(outliers.index, axis = 0)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2,1)\n",
    "    \n",
    "    # Gives space between two subplots\n",
    "    fig.subplots_adjust(hspace = 1) \n",
    "    \n",
    "    # Plot variable with outliers\n",
    "    variable.plot.box(vert = False, color = 'coral', grid = False, ax = ax1, title = 'Distribution with Outliers for %s' %variable.name)\n",
    "\n",
    "    # Plot variable without outliers\n",
    "    filtered.plot.box(vert = False, color = 'coral', grid = False, ax = ax2, title = 'Distribution without Outliers for %s' %variable.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 轮子：缺失值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############库\n",
    "#百度搜索Imupter\n",
    "################按组划分然后用组的平均值来做填补\n",
    "def fill_Age(df):\n",
    "    df.Age = df.Age.fillna(df.groupby(\"Title\").Age.transform(\"median\"))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 轮子：统计数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#4.Create a function to calculate anova between numerical and categorical variable.'''\n",
    "#F检验\n",
    "def anova(nume, cat):\n",
    "    from scipy import stats\n",
    "    grp_nume_by_cat_1 = nume[cat == 1] # Group our numerical variable by categorical variable(1). Group Fair by survivors\n",
    "    grp_nume_by_cat_0 = nume[cat == 0] # Group our numerical variable by categorical variable(0). Group Fare by victims\n",
    "    f_val, p_val = stats.f_oneway(grp_nume_by_cat_1, grp_nume_by_cat_0) # Calculate f statistics and p value\n",
    "    print('Anova results:', f_val, p_val)  \n",
    "    \n",
    "'''#5.Create another function that calculates Tukey's test between our nemurical and categorical variable.'''\n",
    "#T检验\n",
    "def tukey_test(nume, cat):\n",
    "    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "    tukey = pairwise_tukeyhsd(endog = nume,  # Numerical data\n",
    "                             groups = cat,   # Categorical data\n",
    "                             alpha = 0.05)   # Significance level\n",
    "    \n",
    "    summary = tukey.summary()   # See test summary\n",
    "    return display(summary) \n",
    "#P检验\n",
    "def p_test(num,cat):\n",
    "    from scipy import stats\n",
    "    return stats.pearsonre(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 轮子：2X2列联表 分类变量与分类变量的关系刻画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################2X2列联表展示########################################\n",
    "'''#1.Create a function that calculates absolute and relative frequency of Survived variable by a categorical variable. And then plots the absolute and relative frequency of Survived by a categorical variable.'''\n",
    "def crosstab(cat, cat_target):\n",
    "    '''cat = categorical variable, cat_target = our target categorical variable.'''\n",
    "    global ax, ax1\n",
    "    cat_grouped_by_cat_target = pd.crosstab(index = cat, columns = cat_target)\n",
    "    cat_grouped_by_cat_target.rename({0:'Victims', 1:'Survivors'}, axis = 'columns', inplace = True)  # Renaming the columns\n",
    "    pct_cat_grouped_by_cat_target = round(pd.crosstab(index = cat, columns = cat_target, normalize = 'index')*100, 2)\n",
    "    pct_cat_grouped_by_cat_target.rename({0:'Victims(%)', 1:'Survivors(%)'}, axis = 'columns', inplace = True)\n",
    "    print('Survivals and Deaths by', cat.name,':', '\\n',cat_grouped_by_cat_target )\n",
    "    print('\\nPercentage Survivals and Deaths by', cat.name, ':','\\n', pct_cat_grouped_by_cat_target)\n",
    "    \n",
    "    # Plot absolute frequency of Survived by a categorical variable\n",
    "    ax =  cat_grouped_by_cat_target.plot.bar(color = ['r', 'g'])\n",
    "    plt.title('Survival vs Death Count by %s' %cat.name)\n",
    "    abs_bar_labels()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot relative frequrncy of Survived by a categorical variable\n",
    "    ax1 = pct_cat_grouped_by_cat_target.plot.bar(color = ['r', 'g'])\n",
    "    plt.title('Percentage Survival vs Death Count by %s' %cat.name)\n",
    "    pct_bar_labels()\n",
    "    plt.show()\n",
    "###########################################卡方检验#######################################\n",
    "'''#2.Create a function to calculate chi_square test between a categorical and target categorical variable.'''\n",
    "def chi_square(cat, cat_target):\n",
    "    cat_grouped_by_cat_target = pd.crosstab(index = cat, columns = cat_target)\n",
    "    test_result = stats.chi2_contingency (cat_grouped_by_cat_target)\n",
    "    print('Chi_square test result between Survived & %s' %cat.name)\n",
    "    return display(test_result)\n",
    "\n",
    "#############################################bonferroni adjusted检验###############################\n",
    "'''#3.Finally create another function to calculate Bonferroni-adjusted pvalue for a categorical and target categorical variable.'''\n",
    "def bonferroni_adjusted(cat, cat_target):\n",
    "    dummies = pd.get_dummies(cat)\n",
    "    for columns in dummies:\n",
    "        crosstab = pd.crosstab(dummies[columns], cat_target)\n",
    "        print(stats.chi2_contingency(crosstab))\n",
    "    print('\\nColumns:', dummies.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi-square Test: \n",
    "The Chi-square test of independence tests if there is a significant relationship between two categorical variables.The data is usually displayed in a cross-tabulation format with each row representing a category for one variable and each column representing a category for another variable. Chi-square test of independence is an omnibus test.That is it tests the data as a whole. This means that one will not be able to tell which levels (categories) of the variables are responsible for the relationship if the Chi-square table is larger than 2×2. If the test is larger than 2×2, it requires post hoc testing.\n",
    "\n",
    "--The H0 (Null Hypothesis): There is no relationship between variable one and variable two.\n",
    "\n",
    "--The H1 (Alternative Hypothesis): There is a relationship between variable 1 and variable 2.\n",
    "\n",
    "If the p-value is significant (less than 0.05), you can reject the null hypothesis and claim that the findings support the alternate hypothesis. While we check the results of the chi2 test, we need also to check that the expected cell frequencies are greater than or equal to 5. If a cell has an expected frequency less that 5, then the Fisher’s Exact test should be use to overcome this problem.\n",
    "\n",
    "Interpretation of chi-square test outcome: The overall 3x2 table has a chi-square value of 102.889, pvalue of 4.549e-23, degrees of freedom of 2 and the rest are the expected frequencies of array. Since all of the expected frequencies are greater than 5, the chi2 test results can be trusted. We can reject the null hypothesis as the p-value is less than 0.05(infact p value is almost 0). Thus, the results indicate that there is a statistically significant relationship between Pclass and titanic's survivors.\n",
    "\n",
    "# Post Hoc Test: \n",
    "Although our Chi-square test was signficant, since our analysis is 3x2 we don't know which levels of Pclass(1, 2 or 3) have the strongest association with variable Survived. Hence we need to perform a post hoc test to verify if and which combinations are actually significantly associated with Survived. In order to do this, we need to conduct multiple 2×2 Chi-square tests using the Bonferroni-adjusted p-value.\n",
    "\n",
    "To conduct multiple 2×2 Chi-square tests, one needs to regroup the variables for each test to where it is one category against the rest. For us, it will be:\n",
    "\n",
    "*1 vs 2\n",
    "\n",
    "*1 vs 3\n",
    "\n",
    "*2 vs 3\n",
    "\n",
    "Because there are three comparisons, the Bonferroni-adjusted P value needed for significance is 0.05/3, or 0.017. So for our any planned pairwise comparisons to be significant, the p-value must be less than 0.017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 轮子：多个变量的同时影响（共线变量）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create a function that plots the impact of 3 predictor variables at a time on a target variable.'''\n",
    "def multivariate_analysis(cat1, cat2, cat3, cat_target):\n",
    "    grouped = round(pd.crosstab(index = [cat1, cat2, cat3], columns = cat_target, normalize = 'index')*100, 2)\n",
    "    grouped.rename({0:'Died%', 1:'Survived%'}, axis = 1, inplace = True)\n",
    "    ax = grouped.plot.bar(color = ['r', 'g'])\n",
    "    plt.ylabel('Relative Frequency (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 轮子：模型训练的过程(非常重要！)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#1.Create a function that returns train accuracy of different models.'''\n",
    "def train_accuracy(model):\n",
    "        model.fit(X_train, y_train)\n",
    "        train_accuracy = model.score(X_train, y_train)\n",
    "        return train_accuracy\n",
    "    \n",
    "'''#2.Create another function that returns mean cross validation score for different models.'''\n",
    "def x_val_score(model):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    x_val_score = cross_val_score(model, X_train, y_train, cv = 10, scoring = 'accuracy').mean()\n",
    "    return x_val_score\n",
    "\n",
    "'''#3.Create a function to tune hyperparameters of the selected models.'''\n",
    "def tune_hyperparameters(model, params):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    global best_params, best_score\n",
    "    # Construct grid search object with 10 fold cross validation.\n",
    "    grid = GridSearchCV(model, params, verbose = 2, cv = 10, scoring = 'accuracy', n_jobs = -1)\n",
    "    # Fit using grid search.\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_params, best_score = grid.best_params_, grid.best_score_\n",
    "    return best_params, best_score\n",
    "\n",
    "'''#4.Create a function that compares cross validation scores with tunned scores for different models by plotting them.'''\n",
    "def compare_scores(accuracy):\n",
    "    global ax1    \n",
    "    ax1 = accuracy.plot.bar(legend = False, color = ['rosybrown'])\n",
    "    # Removes square brackets and quotes from column name after converting list.\n",
    "    plt.title('Models %s' % ''.join(list(accuracy.columns)))\n",
    "    pct_bar_labels()\n",
    "    plt.ylabel('% Accuracy')\n",
    "    plt.show()\n",
    "    \n",
    "'''#5.Create a function that plot feature importance by the best selected models.'''\n",
    "def plot_feature_importance(model):\n",
    "    importance = pd.DataFrame({'Feature_name': X_train.columns,\n",
    "                              'Importance': np.round(model.feature_importances_,3)})\n",
    "    importance = importance.sort_values(by = 'Importance', ascending = False).set_index('Feature_name')\n",
    "    importance.plot.bar(legend = False, color = ['brown'])\n",
    "    \n",
    "'''#6.This function plots leanring curves for different models.'''\n",
    "def plot_learning_curve(model):\n",
    "    from sklearn.model_selection import learning_curve\n",
    "    # Create feature matrix and target vector\n",
    "    X, y = X_train, y_train\n",
    "    # Create CV training and test scores for various training set sizes\n",
    "    train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv = 10, \n",
    "                                                    scoring='accuracy', n_jobs = -1, \n",
    "                                                    train_sizes = np.linspace(0.01, 1.0, 17))\n",
    "                                                    # 17 different sizes of the training set\n",
    "\n",
    "    # Create means and standard deviations of training set scores\n",
    "    train_mean = np.mean(train_scores, axis = 1)\n",
    "    train_std = np.std(train_scores, axis = 1)\n",
    "\n",
    "    # Create means and standard deviations of test set scores\n",
    "    test_mean = np.mean(test_scores, axis = 1)\n",
    "    test_std = np.std(test_scores, axis = 1)\n",
    "\n",
    "    # Draw lines\n",
    "    plt.plot(train_sizes, train_mean, 'o-', color = 'red',  label = 'Training score')\n",
    "    plt.plot(train_sizes, test_mean, 'o-', color = 'green', label = 'Cross-validation score')\n",
    "    \n",
    "    # Draw bands\n",
    "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha = 0.1, color = 'r') # Alpha controls band transparency.\n",
    "    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha = 0.1, color = 'g')\n",
    "\n",
    "    # Create plot\n",
    "    plt.xlabel('Training Set Size')\n",
    "    plt.ylabel('Accuracy Score') \n",
    "    plt.legend(loc = 'best')\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用\n",
    "##############计算train_accuracy然后计算cross_accuracy然后调整参数######################################\n",
    "\n",
    "\n",
    "##############计算train_accuracy######################################\n",
    "\"\"\"Building machine learning models: \n",
    "We will try 7 different classifiers to find the best classifier after tunning model's hyperparameters that will best generalize the unseen(test) data.\"\"\"\n",
    "\n",
    "'''#1.Logistic Regression'''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_train_accuracy = train_accuracy(LogisticRegression())\n",
    "\n",
    "'''#2.Support Vector Machines'''\n",
    "from sklearn.svm import SVC\n",
    "svm_train_accuracy = train_accuracy(SVC(gamma = 'auto'))\n",
    "\n",
    "'''#3.Random Forest Classifier'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_train_accuracy = train_accuracy(RandomForestClassifier(random_state = 43, n_estimators = 100))\n",
    "\n",
    "'''#4.KNN'''\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_train_accuracy = train_accuracy(KNeighborsClassifier())\n",
    "\n",
    "'''#5.Gaussian Naive Bayes'''\n",
    "from sklearn.naive_bayes import  GaussianNB\n",
    "gnb_train_accuracy = train_accuracy(GaussianNB())\n",
    "\n",
    "'''#6.Decision Tree Classifier'''\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_train_accuracy = train_accuracy(DecisionTreeClassifier(random_state = 43))\n",
    "\n",
    "'''#7.Gradient Boosting Classifier'''\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc_train_accuracy = train_accuracy(GradientBoostingClassifier(random_state = 43))\n",
    "\n",
    "'''Models with best training accuracy:'''\n",
    "train_accuracy = round(pd.DataFrame({'Train_accuracy(%)':[lr_train_accuracy, svm_train_accuracy, rf_train_accuracy, knn_train_accuracy, gnb_train_accuracy, dt_train_accuracy, gbc_train_accuracy]})*100, 2)\n",
    "train_accuracy.index = ['LR', 'SVC', 'RF', 'KNN', 'GNB', 'DT', 'GBC']\n",
    "sorted_train_accuracy = train_accuracy.sort_values(by = 'Train_accuracy(%)', ascending = False) \n",
    "display(sorted_train_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "##############计算cross_accuracy######################################\n",
    "\n",
    "\"\"\"Let's perform k-fold cross validation to find the best classifier with the best cross validation accuracy that will best generalize the previously unseen data.\"\"\"\n",
    "lr_x_val_score  = x_val_score(LogisticRegression())\n",
    "svc_x_val_score = x_val_score(SVC(gamma = 'auto'))\n",
    "rf_x_val_score  = x_val_score(RandomForestClassifier(random_state = 47, n_estimators = 100))\n",
    "knn_x_val_score = x_val_score(KNeighborsClassifier())\n",
    "gnb_x_val_score = x_val_score(GaussianNB())\n",
    "dt_x_val_score  = x_val_score(DecisionTreeClassifier(random_state = 43))\n",
    "gbc_x_val_score = x_val_score(GradientBoostingClassifier(random_state = 43))\n",
    "\n",
    "'''Models with best cross validation score:'''\n",
    "x_val_score = round(pd.DataFrame({'X_val_score(%)':[lr_x_val_score, svc_x_val_score, rf_x_val_score, knn_x_val_score, gnb_x_val_score, dt_x_val_score, gbc_x_val_score]})*100, 2)\n",
    "x_val_score.index = ['LR', 'SVC', 'RF', 'KNN', 'GNB', 'DT', 'GBC']\n",
    "sorted_x_val_score = x_val_score.sort_values(by = 'X_val_score(%)', ascending = False) \n",
    "display(sorted_x_val_score)\n",
    "\n",
    "\n",
    "\n",
    "##############调整参数######################################\n",
    "\"\"\"Define all the models' hyperparameters one by one first::\"\"\"\n",
    "\n",
    "'''Define hyperparameters the logistic regression will be tuned with. For LR, the following hyperparameters are usually tunned.'''\n",
    "lr_params = {'penalty':['l1', 'l2'],\n",
    "             'C': np.logspace(0, 4, 10)}\n",
    "\n",
    "'''For GBC, the following hyperparameters are usually tunned.'''\n",
    "gbc_params = {'learning_rate': [0.01, 0.02, 0.05, 0.01],\n",
    "              'max_depth': [4, 6, 8],\n",
    "              'max_features': [1.0, 0.3, 0.1], \n",
    "              'min_samples_split': [ 2, 3, 4],\n",
    "              'random_state':[43]}\n",
    "\n",
    "'''For SVC, the following hyperparameters are usually tunned.'''\n",
    "svc_params = {'C': [6,7,8,9,10,11,12], \n",
    "              'kernel': ['linear','rbf'],\n",
    "              'gamma': [0.5,0.2,0.1, 0.001, 0.0001]}\n",
    "\n",
    "'''For DT, the following hyperparameters are usually tunned.'''\n",
    "dt_params = {'max_features': ['auto', 'sqrt', 'log2'],\n",
    "             'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n",
    "             'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10,11],\n",
    "             'random_state':[43]}\n",
    "\n",
    "'''For RF, the following hyperparameters are usually tunned.'''\n",
    "rf_params = {'criterion':['gini','entropy'],\n",
    "             'n_estimators':[10,15,20,25,30],\n",
    "             'min_samples_leaf':[1,2,3],\n",
    "             'min_samples_split':[3,4,5,6,7], \n",
    "             'max_features':['sqrt', 'auto', 'log2'],\n",
    "             'random_state':[44]}\n",
    "\n",
    "'''For KNN, the following hyperparameters are usually tunned.'''\n",
    "knn_params = {'n_neighbors':[5,6,7,8,9,10],\n",
    "              'leaf_size':[1,2,3,5],\n",
    "              'weights':['uniform', 'distance'],\n",
    "              'algorithm':['auto', 'ball_tree','kd_tree','brute']}\n",
    "\n",
    "'''Tune LR hyperparameters.'''\n",
    "tune_hyperparameters(LogisticRegression(), params = lr_params)\n",
    "lr_best_params, lr_best_score = best_params, best_score\n",
    "print('Best score:', lr_best_score)\n",
    "print('Best parameters:', lr_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 轮子：各种需要的结果图和结果（重要）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Return prediction to use it in another function.'''\n",
    "def x_val_predict(model):\n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    predicted = cross_val_predict(model, X_train, y_train, cv = 10)\n",
    "    return predicted # Now we can use it in another function by assigning the function to its return value.\n",
    "\n",
    "'''#1.Confusion matrix.'''\n",
    "def confusion_matrix(model):\n",
    "    predicted = x_val_predict(model)\n",
    "    confusion_matrix = pd.crosstab(y_train, predicted, rownames = ['Actual'], colnames = ['Predicted/Classified'], margins = True) # We use pandas crosstab\n",
    "    return display(confusion_matrix)\n",
    "\n",
    "'''#2.Precision score.'''\n",
    "def precision_score(model):\n",
    "    from sklearn.metrics import precision_score\n",
    "    predicted = x_val_predict(model)\n",
    "    precision_score = precision_score(y_train, predicted)\n",
    "    return display(precision_score)\n",
    "\n",
    "'''#3.Recall score.'''\n",
    "def recall_score(model):\n",
    "    from sklearn.metrics import recall_score\n",
    "    predicted = x_val_predict(model)\n",
    "    recall_score = recall_score(y_train, predicted)\n",
    "    return display(recall_score) \n",
    "\n",
    "'''#4.Specificity score.'''\n",
    "def specificity_score(model):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    predicted = x_val_predict(model)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_train, predicted).ravel()\n",
    "    specificity_score = tn / (tn + fp)\n",
    "    return display(specificity_score)\n",
    "\n",
    "'''#5.F1 score.'''\n",
    "def f1_score(model):\n",
    "    from sklearn.metrics import f1_score\n",
    "    predicted = x_val_predict(model)\n",
    "    f1_score = f1_score(y_train, predicted)\n",
    "    return display(f1_score)\n",
    "\n",
    "'''#6.Classification report.'''\n",
    "def classification_report(model):\n",
    "    from sklearn.metrics import classification_report\n",
    "    predicted = x_val_predict(model)\n",
    "    classification_report = classification_report(y_train, predicted)\n",
    "    return print(classification_report)\n",
    "\n",
    "'''#7.Plot precision-recall vs threshold curve.'''\n",
    "def precision_recall_vs_threshold(model):\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    probablity = model.predict_proba(X_train)[:, 1]\n",
    "    precision, recall, threshold = precision_recall_curve(y_train, probablity)\n",
    "    plt.figure(figsize = (18, 4))\n",
    "    plt.plot(threshold, precision[:-1], 'b-', label = 'precision', lw = 3.7)\n",
    "    plt.plot(threshold, recall[:-1], 'g', label = 'recall', lw = 3.7)\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.ylim([0, 1])\n",
    "    \n",
    "'''#8.Plot recall vs precision curve.'''\n",
    "def plot_precision_vs_recall(model):\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    probablity = model.predict_proba(X_train)[:, 1]\n",
    "    precision, recall, threshold = precision_recall_curve(y_train, probablity)\n",
    "    plt.figure(figsize = (18, 5))\n",
    "    plt.plot(recall, precision, 'r-', lw = 3.7)\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Precision')\n",
    "    plt.axis([0, 1.5, 0, 1.5])\n",
    "\n",
    "'''#9.Plot ROC curve with AUC score.'''\n",
    "def plot_roc_and_auc_score(model):\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score\n",
    "    probablity = model.predict_proba(X_train)[:, 1]\n",
    "    false_positive_rate, true_positive_rate, threshold = roc_curve(y_train, probablity)\n",
    "    auc_score = roc_auc_score(y_train, probablity)\n",
    "    plt.figure(figsize = (18, 5))\n",
    "    plt.plot(false_positive_rate, true_positive_rate, label = \"ROC CURVE, AREA = \"+ str(auc_score))\n",
    "    plt.plot([0, 1], [0, 1], 'black', lw = 3.7)\n",
    "    plt.xlabel('False Positive Rate (1-Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.legend(loc = 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 算法模型比较！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from xgboost import XGBClassifier\n",
    "#Machine Learning Algorithm (MLA) Selection and Initialization\n",
    "MLA = [\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "\n",
    "    #Gaussian Processes\n",
    "    gaussian_process.GaussianProcessClassifier(),\n",
    "    \n",
    "    #GLM\n",
    "    linear_model.LogisticRegressionCV(),\n",
    "    linear_model.PassiveAggressiveClassifier(),\n",
    "    linear_model.RidgeClassifierCV(),\n",
    "    linear_model.SGDClassifier(),\n",
    "    linear_model.Perceptron(),\n",
    "    \n",
    "    #Navies Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    \n",
    "    #Nearest Neighbor\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    \n",
    "    #SVM\n",
    "    svm.SVC(probability=True),\n",
    "    svm.NuSVC(probability=True),\n",
    "    svm.LinearSVC(),\n",
    "    \n",
    "    #Trees    \n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "    \n",
    "    #Discriminant Analysis\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "    \n",
    "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "    XGBClassifier()    \n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
    "#note: this is an alternative to train_test_split\n",
    "cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n",
    "\n",
    "#create table to compare MLA metrics\n",
    "MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "#create table to compare MLA predictions\n",
    "MLA_predict = data1[Target]\n",
    "\n",
    "#index through MLA and save performance to table\n",
    "row_index = 0\n",
    "for alg in MLA:\n",
    "\n",
    "    #set name and parameters\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "    \n",
    "    #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "    cv_results = model_selection.cross_validate(alg, data1[data1_x_bin], data1[Target], cv  = cv_split)\n",
    "\n",
    "    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n",
    "    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
    "    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
    "    \n",
    "\n",
    "    #save MLA predictions - see section 6 for usage\n",
    "    alg.fit(data1[data1_x_bin], data1[Target])\n",
    "    MLA_predict[MLA_name] = alg.predict(data1[data1_x_bin])\n",
    "    \n",
    "    row_index+=1\n",
    "\n",
    "    \n",
    "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
    "MLA_compare\n",
    "#MLA_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####注意这里的make_scorer就可以利用metric的所有评价函数\n",
    "\n",
    "cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 )\n",
    "scorer = make_scorer(f1_score)\n",
    "\n",
    "tune_model = model_selection.GridSearchCV(gbm, param_grid=gbm_params_estimator_learningrate, scoring = scorer, cv = cv_split)\n",
    "tune_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# voting 策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#why choose one model, when you can pick them all with voting classifier\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n",
    "#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\n",
    "vote_est = [\n",
    "    #Ensemble Methods: http://scikit-learn.org/stable/modules/ensemble.html\n",
    "    ('ada', ensemble.AdaBoostClassifier()),\n",
    "    ('bc', ensemble.BaggingClassifier()),\n",
    "    ('etc',ensemble.ExtraTreesClassifier()),\n",
    "    ('gbc', ensemble.GradientBoostingClassifier()),\n",
    "    ('rfc', ensemble.RandomForestClassifier()),\n",
    "\n",
    "    #Gaussian Processes: http://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process-classification-gpc\n",
    "    ('gpc', gaussian_process.GaussianProcessClassifier()),\n",
    "    \n",
    "    #GLM: http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "    ('lr', linear_model.LogisticRegressionCV()),\n",
    "    \n",
    "    #Navies Bayes: http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "    ('bnb', naive_bayes.BernoulliNB()),\n",
    "    ('gnb', naive_bayes.GaussianNB()),\n",
    "    \n",
    "    #Nearest Neighbor: http://scikit-learn.org/stable/modules/neighbors.html\n",
    "    ('knn', neighbors.KNeighborsClassifier()),\n",
    "    \n",
    "    #SVM: http://scikit-learn.org/stable/modules/svm.html\n",
    "    ('svc', svm.SVC(probability=True)),\n",
    "    \n",
    "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "   ('xgb', XGBClassifier())\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "#Hard Vote or majority rules\n",
    "vote_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')\n",
    "vote_hard_cv = model_selection.cross_validate(vote_hard, data1[data1_x_bin], data1[Target], cv  = cv_split)\n",
    "vote_hard.fit(data1[data1_x_bin], data1[Target])\n",
    "\n",
    "print(\"Hard Voting Training w/bin score mean: {:.2f}\". format(vote_hard_cv['train_score'].mean()*100)) \n",
    "print(\"Hard Voting Test w/bin score mean: {:.2f}\". format(vote_hard_cv['test_score'].mean()*100))\n",
    "print(\"Hard Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_hard_cv['test_score'].std()*100*3))\n",
    "print('-'*10)\n",
    "\n",
    "\n",
    "#Soft Vote or weighted probabilities\n",
    "vote_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')\n",
    "vote_soft_cv = model_selection.cross_validate(vote_soft, data1[data1_x_bin], data1[Target], cv  = cv_split)\n",
    "vote_soft.fit(data1[data1_x_bin], data1[Target])\n",
    "\n",
    "print(\"Soft Voting Training w/bin score mean: {:.2f}\". format(vote_soft_cv['train_score'].mean()*100)) \n",
    "print(\"Soft Voting Test w/bin score mean: {:.2f}\". format(vote_soft_cv['test_score'].mean()*100))\n",
    "print(\"Soft Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_soft_cv['test_score'].std()*100*3))\n",
    "print('-'*10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
